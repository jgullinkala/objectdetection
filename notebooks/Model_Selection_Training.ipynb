{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Bosie Akioyamen\n",
    "\n",
    "This Module ```Model_Selection_Training``` does Modeling and Evaluation:\n",
    "1. Modeling:\n",
    "    - Chooses suitable machine learning algorithms for classification and detection (e.g., CNNs for image data, object detection algorithms like YOLO or SSD).\n",
    "    - Train multiple models to compare their performance.\n",
    "    - Fine-tune hyperparameters to improve model accuracy.\n",
    "2. Evaluation:\n",
    "    - Evaluate the models using appropriate metrics (e.g., accuracy, precision, recall, F1 score, mean average precision for object detection).\n",
    "    - Document the modeling and evaluation process in a Jupyter Notebook.\n",
    "3. Deliverables:\n",
    "    - Jupyter Notebook with modeling and evaluation steps.\n",
    "    - Summary of model performance and comparison for the business presentation and written report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import glob\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.ops import nms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import IPython\n",
    "import time\n",
    "\n",
    "# Checking device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define directories and read labels\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_dir = os.path.join(project_root, 'data')\n",
    "image_dir = os.path.join(data_dir, 'downloaded_images', 'images')\n",
    "label_file = os.path.join(data_dir, 'labels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels...\n",
      "Initial labels dataframe loaded.\n",
      "Preprocessing labels...\n",
      "Labels preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading labels...\")\n",
    "df = pd.read_csv(label_file)\n",
    "print(\"Initial labels dataframe loaded.\")\n",
    "\n",
    "# Preprocess labels\n",
    "print(\"Preprocessing labels...\")\n",
    "df = df[df['xmin'] >= 0]\n",
    "df = df[df['ymin'] >= 0]\n",
    "df = df[df['xmax'] > df['xmin']]\n",
    "df = df[df['ymax'] > df['ymin']]\n",
    "df = df[:60000]\n",
    "print(\"Labels preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling new_df function...\n",
      "Normalizing bounding boxes...\n"
     ]
    }
   ],
   "source": [
    "# Normalize bounding boxes\n",
    "def new_df(df):\n",
    "    print(\"Normalizing bounding boxes...\")\n",
    "    for (i, fname) in list(enumerate(df.frame.values)):\n",
    "        fpath = os.path.join(image_dir, fname)\n",
    "        img = np.asarray(Image.open(fpath))\n",
    "        h, w, _ = img.shape\n",
    "        df['xmin'].iloc[i] = df['xmin'].iloc[i] / w\n",
    "        df['xmax'].iloc[i] = df['xmax'].iloc[i] / w\n",
    "        df['ymin'].iloc[i] = df['ymin'].iloc[i] / h\n",
    "        df['ymax'].iloc[i] = df['ymax'].iloc[i] / h\n",
    "    print(\"Bounding boxes normalized.\")\n",
    "    return df\n",
    "\n",
    "print(\"Calling new_df function...\")\n",
    "df1 = new_df(df)\n",
    "print(\"Dataframe df1 created with normalized bounding boxes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe\n",
    "print(\"Filtering dataframe df1...\")\n",
    "df1 = df1[df1['xmin'] >= 0.1]\n",
    "df1 = df1[df1['xmax'] >= 0.1]\n",
    "df1 = df1[df1['ymin'] >= 0.1]\n",
    "df1 = df1[df1['ymax'] >= 0.1]\n",
    "print(f\"Number of rows in df1 after filtering: {len(df1)}\")\n",
    "\n",
    "# Define labels\n",
    "labels = {0: 'background', 1: 'car', 2: 'truck', 3: 'pedestrian', 4: 'bicyclist', 5: 'light'}\n",
    "target2labels = labels.copy()\n",
    "num_classes = len(labels)\n",
    "print(f\"Labels defined: {target2labels}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Display sample image\n",
    "image_path = os.path.join(image_dir, '1478019952686311006.jpg')\n",
    "img = cv2.imread(image_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "plt.figure(figsize=(10, 13))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(f\"Sample image shape: {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = torch.tensor(img).permute(2, 0, 1)\n",
    "    return img.to(device).float()\n",
    "\n",
    "# Define dataset class\n",
    "class SelfDrivingCarDataset(Dataset):\n",
    "    w, h = 224, 224\n",
    "    \n",
    "    def __init__(self, df, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.files = glob.glob(os.path.join(self.image_dir, '*.jpg'))\n",
    "        self.image_infos = df.frame.unique()\n",
    "        print(f\"Dataset initialized with {len(self.image_infos)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_infos)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        img_id = self.image_infos[ix]\n",
    "        img_path = os.path.join(self.image_dir, img_id)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = np.array(img.resize((self.w, self.h), resample=Image.BILINEAR)) / 255.\n",
    "        data = self.df[self.df['frame'] == img_id]\n",
    "        labels = data['class_id'].values.tolist()\n",
    "        data = data[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "        data[:, [0, 2]] *= self.w\n",
    "        data[:, [1, 3]] *= self.h\n",
    "        boxes = data.astype(np.uint32).tolist()\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.Tensor(boxes).float()\n",
    "        target[\"labels\"] = torch.Tensor([i for i in labels]).long()\n",
    "        img = self.preprocess_image(img)\n",
    "        return img, target\n",
    "\n",
    "    def preprocess_image(self, img):\n",
    "        img = torch.tensor(img).permute(2, 0, 1)\n",
    "        return img.to(device).float()\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        images = []\n",
    "        targets = []\n",
    "        for img, target in batch:\n",
    "            images.append(img)\n",
    "            targets.append(target)\n",
    "        return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting data into training and validation sets...\")\n",
    "trn_ids, val_ids = train_test_split(df1.frame.unique(), test_size=0.1, random_state=99)\n",
    "trn_df, val_df = df1[df1['frame'].isin(trn_ids)], df1[df1['frame'].isin(val_ids)]\n",
    "print(f\"Training set: {len(trn_df)} samples, Validation set: {len(val_df)} samples\")\n",
    "\n",
    "train_ds = SelfDrivingCarDataset(trn_df, image_dir)\n",
    "val_ds = SelfDrivingCarDataset(val_df, image_dir)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, collate_fn=train_ds.collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, collate_fn=val_ds.collate_fn, drop_last=True)\n",
    "print(\"Data loaders created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "def get_model():\n",
    "    print(\"Loading model...\")\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    print(\"Model loaded.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(inputs, targets, model, optimizer):\n",
    "    model.train()\n",
    "    inputs = list(image.to(device) for image in inputs)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    optimizer.zero_grad()\n",
    "    losses = model(inputs, targets)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, losses\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_batch(inputs, targets, model):\n",
    "    model.eval()\n",
    "    inputs = list(image.to(device) for image in inputs)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    losses = model(inputs, targets)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    return loss, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=1):\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            try:\n",
    "                loss, _ = train_batch(inputs, targets, model, optimizer)\n",
    "                train_loss += loss.item()\n",
    "                if i % 10 == 0:  # Print every 10 batches\n",
    "                    print(f'Batch {i}/{len(train_loader)}, Loss: {loss.item()}')\n",
    "            except Exception as e:\n",
    "                print(f\"Error during training batch {i}: {e}\")\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                loss, _ = validate_batch(inputs, targets, model)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Time: {time.time() - start_time:.2f}s')\n",
    "\n",
    "        # Evaluate model after each epoch\n",
    "        print('Evaluation on validation set:')\n",
    "        evaluate_model(model, val_loader)\n",
    "\n",
    "    print('Training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def calculate_metrics(true_labels, pred_labels):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "    return precision, recall, f1\n",
    "\n",
    "def get_predictions(model, data_loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = list(image.to(device) for image in inputs)\n",
    "            outputs = model(inputs)\n",
    "            for target, output in zip(targets, outputs):\n",
    "                true_labels.extend(target['labels'].cpu().numpy())\n",
    "                pred_labels.extend(output['labels'].cpu().numpy())\n",
    "    return true_labels, pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    true_labels, pred_labels = get_predictions(model, data_loader)\n",
    "    precision, recall, f1 = calculate_metrics(true_labels, pred_labels)\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=labels.values()))\n",
    "\n",
    "    # Example of hazard classification and severity assessment\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = list(image.to(device) for image in inputs)\n",
    "            outputs = model(inputs)\n",
    "            for output in outputs:\n",
    "                labels = output['labels'].cpu().numpy()\n",
    "                boxes = output['boxes'].cpu().numpy()\n",
    "                for label, box in zip(labels, boxes):\n",
    "                    object_type = target2labels[label.item()]\n",
    "                    bbox = [int(coord) for coord in box]\n",
    "                    image_size = (224, 224)  # Assuming fixed size for this example\n",
    "\n",
    "                    # Example usage of assess_severity\n",
    "                    severity = assess_severity({\n",
    "                        \"type\": object_type,\n",
    "                        \"bbox\": bbox,\n",
    "                        \"image_size\": image_size\n",
    "                    })\n",
    "                    \n",
    "                    # Example usage of classify_hazard\n",
    "                    hazard_classification = classify_hazard(object_type)\n",
    "                    \n",
    "                    print(f'Object: {object_type}, Hazard Classification: {hazard_classification}, Severity: {severity}')\n",
    "\n",
    "                    # You can store or further process the hazard classifications and severity assessments as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_hazard(object_type):\n",
    "    hazardous_objects = ['car', 'truck', 'pedestrian']\n",
    "    return 'hazardous' if object_type in hazardous_objects else 'non-hazardous'\n",
    "\n",
    "def assess_severity(object_info):\n",
    "    bbox = object_info['bbox']\n",
    "    image_size = object_info['image_size']\n",
    "    object_type = object_info['type']\n",
    "\n",
    "    # Calculate the center of the bounding box\n",
    "    bbox_center_x = (bbox[0] + bbox[2]) / 2\n",
    "    bbox_center_y = (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "    # Calculate the distance from the center of the image to the center of the bounding box\n",
    "    image_center_x = image_size[0] / 2\n",
    "    image_center_y = image_size[1] / 2\n",
    "    distance_to_center = ((bbox_center_x - image_center_x) ** 2 + (bbox_center_y - image_center_y) ** 2) ** 0.5\n",
    "\n",
    "    # Calculate the area of the bounding box\n",
    "    bbox_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "\n",
    "    # Normalize distance and area\n",
    "    normalized_distance = distance_to_center / ((image_size[0] ** 2 + image_size[1] ** 2) ** 0.5)\n",
    "    normalized_area = bbox_area / (image_size[0] * image_size[1])\n",
    "\n",
    "    # Define thresholds for severity\n",
    "    distance_threshold = 0.5  # Adjusted to consider objects further from the center\n",
    "    area_threshold = 0.05\n",
    "\n",
    "    if normalized_distance < distance_threshold and normalized_area > area_threshold:\n",
    "        severity = 'high'\n",
    "    elif normalized_distance < distance_threshold or normalized_area > area_threshold:\n",
    "        severity = 'medium'\n",
    "    else:\n",
    "        severity = 'low'\n",
    "\n",
    "    return severity\n",
    "\n",
    "# Example usage\n",
    "object_info = {\n",
    "    \"type\": \"car\",\n",
    "    \"bbox\": [50, 50, 150, 150],  # Near the top-left corner\n",
    "    \"image_size\": [800, 600]\n",
    "}\n",
    "\n",
    "print(classify_hazard(object_info['type']))  # Output: 'hazardous'\n",
    "print(assess_severity(object_info))          # Output: 'medium' (for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "num_epochs = 1\n",
    "print(f'Starting training for {num_epochs} epochs...')\n",
    "model = get_model().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "train_model(model, train_loader, val_loader, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "# Evaluate model\n",
    "print('Final evaluation on validation set:')\n",
    "evaluate_model(model, val_loader)\n",
    "\n",
    "print('Training and evaluation complete.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
